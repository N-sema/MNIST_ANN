{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpM5n6j7vavhiZKd8aUNvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N-sema/MNIST_ANN/blob/main/MNIST_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU3kq3MJ6tAA"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MNIST veri seti\n",
        "\n",
        "image processing:\n",
        "histogram eşitleme : kontrast iyileştirme\n",
        "gaussian blur gürültü azaltma\n",
        "canny edge detection kenar tespiti\n",
        "\n",
        "ANN ile MNIST veri setini sınıflandırma\n",
        "\n",
        "Libraies :\n",
        "tenserflow : KERAS ile aNN modeli oluşturma ve eğitim\n",
        "matplotlib : görselleştirme\n",
        "cv2 : opencv görüntü işleme (iimage processing)\n",
        "\"\"\"\n",
        "\n",
        "!pip install tensorflow matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential # ANN modeli için\n",
        "from tensorflow.keras.layers import Dense, Dropout # ANN katmanları için\n",
        "from tensorflow.keras.optimizers import Adam # optimizer\n"
      ],
      "metadata": {
        "id": "ps1ibF6s_I5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print (f\"x_train shape : {x_train.shape}\")\n",
        "print (f\"y_train shape : {y_train.shape}\")\n",
        "\n",
        "\"\"\"\n",
        "x_train shape : (60000, 28, 28)\n",
        "y_train shape : (60000,) bu bir vektör olduğunu gösteriyor\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xrK5hVCvA5lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image preprocessing\n",
        "img = x_train[0] # ilk resmi al\n",
        "stages = {\"orijinal\" : img}\n",
        "\n",
        "#histogram eşitleme\n",
        "eq = cv2.equalizeHist(img) #histogram eşitleme\n",
        "stages[\"Histogram eşitleme\"]= eq\n",
        "\n",
        "#gaussian blur : gürültüyü azaltma\n",
        "blur = cv2.GaussianBlur(eq,(5,5),0) #0 ortalamalı\n",
        "stages [\"gaussian blur \"]= blur\n",
        "\n",
        "#canny ile kenar tespiti\n",
        "edges = cv2.Canny(blur,50,150) #kenar tespiti 50 ve 150 alt ve üst eşik değerleri\n",
        "# piksel farkından ötürü 150 ve üstündeki değerler kenar kabul edilir\n",
        "stages[\"canny kenarları\"] = edges\n",
        "\n",
        "# gorselleştirme\n",
        "fig, axes = plt.subplots(2,2, figsize= (6,6)) # 2,2  = 2 satır 2 sütün dan 4 grid oluşur\n",
        "axes= axes.flat\n",
        "for ax,(title,im) in zip(axes, stages.items()):\n",
        "  ax.imshow (im,cmap = \"gray\")\n",
        "  ax.set_title(title)\n",
        "  ax.axis(\"off\")\n",
        "plt.suptitle(\"MNİST Image Processing Stages\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#preprocessing fonksiyonu\n",
        "\n",
        "def preprocess_image(img):\n",
        "  \"\"\"\n",
        "  -histogram eşitleme\n",
        "  -gaussian blur\n",
        "  -canny ile kenar tespiti\n",
        "  -flattering: 28x28 boyutundan 784 boyutuna cevirme\n",
        "  -normalizasyon : 0-255 arasından 0-1 arasina cevirme\n",
        "  \"\"\"\n",
        "\n",
        "  img_eq= cv2.equalizeHist(img) #histogram eşitleme\n",
        "  img_blur = cv2.GaussianBlur(img_eq, (5,5),0) # gaussian blur\n",
        "  img_edges = cv2.Canny(img_blur, 50,150 ) # canny kenar tespiti\n",
        "  features= img_edges.flatten()/255.0 # flattering\n",
        "  return features\n",
        "\n",
        "num_train=10000\n",
        "num_test=2000\n",
        "\n",
        "X_train = np.array([preprocess_image(img) for img in x_train[:num_train]])\n",
        "y_train_sub= y_train[:num_train]\n",
        "\n",
        "X_test =np.array([preprocess_image(img) for img in x_test[:num_test] ])\n",
        "y_test_sub= y_test[:num_test]\n",
        "\n"
      ],
      "metadata": {
        "id": "Mn151A4qBvLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN model creation\n",
        "model = Sequential([\n",
        "    Dense(128 , activation=\"relu\", input_shape= (784,)), #ilk katman , 128 nöron 28x28 = 784 boyutunda\n",
        "    Dropout(0.5), #dropout katmanı overfiitingi azaltmak için , %50 dropout\n",
        "    Dense(64,activation=\"relu\") , # ikinci katman 64 nöron\n",
        "    Dense (10, activation=\"softmax\") # cıkıs katmanı 10 nöron (0-9 rakamları totoalde 10 sınıf olduğu için 10 olmak zorunda )\n",
        "\n",
        "])\n",
        "\n",
        "#compile model\n",
        "model.compile(\n",
        "    optimizer= Adam(learning_rate=0.001), # optimizer\n",
        "    loss= \"sparse_categorical_crossentropy\", # kayıp fonksiyonu\n",
        "    metrics= [\"accuracy\"] # metrikler\n",
        ")\n",
        "\n",
        "print(model.summary()) # nasıl bir model inşa ettiğimizi gösterir\n"
      ],
      "metadata": {
        "id": "rSlEFIiUGGA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ann model training\n",
        "history = model.fit(\n",
        "    X_train, y_train_sub,\n",
        "    validation_data= (X_test, y_test_sub),\n",
        "    epochs= 10,\n",
        "    batch_size=32,\n",
        "    verbose = 2 # eğitim sırasında ekrana ne kadar ve nasıl bilgi yazdırılacağını belirler.\n",
        "#Yani tamamen çıktı seviyesi — modele veya öğrenmeye hiçbir etkisi yok.\n",
        ")\n",
        "# 4 epochtan sonra overfitting başladı accurcy val den yüksek\n"
      ],
      "metadata": {
        "id": "VHfbUqTsNtbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model performance\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_sub)\n",
        "print (f\"Test loss : {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "#plot training history\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history[\"loss\"], label= \"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"] ,label=\"Validation Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history[\"accuracy\"], label= \"Training Accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label= \"Vakidation Accuracy\")\n",
        "plt.title (\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout() # figür içinde bulunanları sıkıştırır\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SZnuMl9gPwin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}